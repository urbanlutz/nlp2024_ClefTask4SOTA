{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if os.getcwd() == '/home/user/code':\n",
    "    os.chdir('/home/user/code/nlp2024_ClefTask4SOTA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Load a specific run\n",
    "\n",
    "runs = [\n",
    "    \"VAL_naive_doctaet-simple_zs-mistralaiMistral7BInstructv03-20240611-095123\",\n",
    "    \"VAL_naive_doctaet-simple_fs-mistralaiMistral7BInstructv03-20240611-102154\",\n",
    "    \"VAL_naive_doctaet-simple_zs-googlegemma7bit-20240611-130659\",\n",
    "    \"VAL_naive_doctaet-simple_fs-googlegemma7bit-20240611-133609\",\n",
    "    \"VAL_llama3_70b_fewshot_optimized02-20240531-105142\",\n",
    "    \"VAL_llama3_8b_few_shot_template_initial-20240604-125136\"\n",
    "]\n",
    "\n",
    "# Top runs on Test:\n",
    "# - TEST_llama3_70b_fewshot_initial-20240601-211554\n",
    "dfs = []\n",
    "\n",
    "for run in runs:\n",
    "    path = f\"results/{run}/df.feather\"\n",
    "\n",
    "    df = pd.read_feather(path)\n",
    "    try:\n",
    "        df = df.rename({\"annontation\": \"annotation\"}, axis=1) # typo in early versions\n",
    "    except:\n",
    "        pass\n",
    "    dfs.append(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in dfs:\n",
    "    df[\"annotation\"] = df[\"annotation\"].apply(format)\n",
    "    df[\"annotation\"] = df[\"annotation\"].astype(pd.StringDtype())\n",
    "    df[\"ground_truth\"] = df[\"ground_truth\"].astype(pd.StringDtype())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "run             object\n",
       "f               object\n",
       "annotation      string\n",
       "ground_truth    string\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>general_accuracy</th>\n",
       "      <th>exact_recalls_task</th>\n",
       "      <th>exact_recalls_dataset</th>\n",
       "      <th>exact_recalls_metric</th>\n",
       "      <th>exact_recalls_Score</th>\n",
       "      <th>exact_recalls_overall</th>\n",
       "      <th>partial_recalls_task</th>\n",
       "      <th>partial_recalls_dataset</th>\n",
       "      <th>partial_recalls_metric</th>\n",
       "      <th>partial_recalls_Score</th>\n",
       "      <th>...</th>\n",
       "      <th>partial_f1s_metric</th>\n",
       "      <th>partial_f1s_Score</th>\n",
       "      <th>partial_f1s_overall</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "      <th>run</th>\n",
       "      <th>score</th>\n",
       "      <th>num_samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51.0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>4.93</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.97</td>\n",
       "      <td>6.40</td>\n",
       "      <td>0.99</td>\n",
       "      <td>4.93</td>\n",
       "      <td>0.97</td>\n",
       "      <td>...</td>\n",
       "      <td>5.35</td>\n",
       "      <td>1.50</td>\n",
       "      <td>3.81</td>\n",
       "      <td>18.73</td>\n",
       "      <td>11.54</td>\n",
       "      <td>17.80</td>\n",
       "      <td>17.47</td>\n",
       "      <td>VAL_naive_doctaet-simple_zs-mistralaiMistral7B...</td>\n",
       "      <td>3.81</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>34.51</td>\n",
       "      <td>14.45</td>\n",
       "      <td>33.73</td>\n",
       "      <td>33.71</td>\n",
       "      <td>VAL_naive_doctaet-simple_fs-mistralaiMistral7B...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.15</td>\n",
       "      <td>13.28</td>\n",
       "      <td>2.28</td>\n",
       "      <td>11.40</td>\n",
       "      <td>11.30</td>\n",
       "      <td>VAL_naive_doctaet-simple_zs-googlegemma7bit-20...</td>\n",
       "      <td>0.15</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.49</td>\n",
       "      <td>16.87</td>\n",
       "      <td>1.52</td>\n",
       "      <td>16.16</td>\n",
       "      <td>16.11</td>\n",
       "      <td>VAL_naive_doctaet-simple_fs-googlegemma7bit-20...</td>\n",
       "      <td>0.49</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>49.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>49.00</td>\n",
       "      <td>49.00</td>\n",
       "      <td>VAL_llama3_70b_fewshot_optimized02-20240531-10...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69.0</td>\n",
       "      <td>4.93</td>\n",
       "      <td>13.79</td>\n",
       "      <td>7.39</td>\n",
       "      <td>1.97</td>\n",
       "      <td>7.02</td>\n",
       "      <td>10.84</td>\n",
       "      <td>14.78</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1.94</td>\n",
       "      <td>...</td>\n",
       "      <td>7.16</td>\n",
       "      <td>1.43</td>\n",
       "      <td>6.91</td>\n",
       "      <td>34.03</td>\n",
       "      <td>7.58</td>\n",
       "      <td>33.12</td>\n",
       "      <td>33.04</td>\n",
       "      <td>VAL_llama3_8b_few_shot_template_initial-202406...</td>\n",
       "      <td>6.91</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   general_accuracy  exact_recalls_task  exact_recalls_dataset  \\\n",
       "0              51.0                0.99                   0.99   \n",
       "0              64.0                0.00                   0.00   \n",
       "0              51.0                0.00                   0.00   \n",
       "0              58.0                0.00                   0.00   \n",
       "0              49.0                0.00                   0.00   \n",
       "0              69.0                4.93                  13.79   \n",
       "\n",
       "   exact_recalls_metric  exact_recalls_Score  exact_recalls_overall  \\\n",
       "0                  4.93                 0.99                   1.97   \n",
       "0                  0.00                 0.00                   0.00   \n",
       "0                  0.00                 0.00                   0.00   \n",
       "0                  0.00                 0.00                   0.00   \n",
       "0                  0.00                 0.00                   0.00   \n",
       "0                  7.39                 1.97                   7.02   \n",
       "\n",
       "   partial_recalls_task  partial_recalls_dataset  partial_recalls_metric  \\\n",
       "0                  6.40                     0.99                    4.93   \n",
       "0                  0.00                     0.00                    0.00   \n",
       "0                  0.49                     0.00                    0.00   \n",
       "0                  0.49                     0.00                    0.49   \n",
       "0                  0.00                     0.00                    0.00   \n",
       "0                 10.84                    14.78                    8.87   \n",
       "\n",
       "   partial_recalls_Score  ...  partial_f1s_metric  partial_f1s_Score  \\\n",
       "0                   0.97  ...                5.35               1.50   \n",
       "0                   0.00  ...                0.00               0.00   \n",
       "0                   0.00  ...                0.00               0.00   \n",
       "0                   0.00  ...                0.98               0.00   \n",
       "0                   0.00  ...                0.00               0.00   \n",
       "0                   1.94  ...                7.16               1.43   \n",
       "\n",
       "   partial_f1s_overall  rouge1  rouge2  rougeL  rougeLsum  \\\n",
       "0                 3.81   18.73   11.54   17.80      17.47   \n",
       "0                 0.00   34.51   14.45   33.73      33.71   \n",
       "0                 0.15   13.28    2.28   11.40      11.30   \n",
       "0                 0.49   16.87    1.52   16.16      16.11   \n",
       "0                 0.00   49.00    0.00   49.00      49.00   \n",
       "0                 6.91   34.03    7.58   33.12      33.04   \n",
       "\n",
       "                                                 run  score  num_samples  \n",
       "0  VAL_naive_doctaet-simple_zs-mistralaiMistral7B...   3.81          100  \n",
       "0  VAL_naive_doctaet-simple_fs-mistralaiMistral7B...   0.00          100  \n",
       "0  VAL_naive_doctaet-simple_zs-googlegemma7bit-20...   0.15          100  \n",
       "0  VAL_naive_doctaet-simple_fs-googlegemma7bit-20...   0.49          100  \n",
       "0  VAL_llama3_70b_fewshot_optimized02-20240531-10...   0.00          100  \n",
       "0  VAL_llama3_8b_few_shot_template_initial-202406...   6.91          100  \n",
       "\n",
       "[6 rows x 38 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate\n",
    "from scoring_program.evaluation import Metrics\n",
    "\n",
    "results = []\n",
    "for df in dfs:\n",
    "    result = Metrics.evaluate_property_wise_json_based(\n",
    "        label_list=list(df[\"ground_truth\"]), prediction_list=list(df[\"annotation\"])\n",
    "    )\n",
    "\n",
    "    result.update(\n",
    "        Metrics.evaluate_rouge(label_list=list(df[\"ground_truth\"]), prediction_list=list(df[\"annotation\"]))\n",
    "    )\n",
    "    result[\"run\"] = df[\"run\"][0]\n",
    "    result[\"score\"] = result[\"partial_f1s_overall\"]\n",
    "    result[\"num_samples\"] = len(df)\n",
    "    results.append(pd.DataFrame([result]))\n",
    "\n",
    "df_res = pd.concat(results)\n",
    "df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"[{'LEADERBOARD': {'Task': 'Illumination of Monotone Orthogonal Polygons', 'Dataset': 'Monotone Orthogonal Polygons', 'Metric': '', 'Score': ''}}, {'LEADERBOARD': {'Task': 'Illumination of Monotone Polygons', 'Dataset': 'Monotone Polygons', 'Metric': '', 'Score': ''}}]\",\n",
       " 'unanswerable\\n',\n",
       " \"[{'LEADERBOARD': {'Task': 'Lecture Transcripts', 'Dataset': 'arXIV', 'Metric': 'ROUGE-2', 'Score': '16.71'}}, {'LEADERBOARD': {'Task': 'Lecture Transcripts', 'Dataset': 'arXiv', 'Metric': 'ROUGE-1', 'Score': '42.10'}}, {'LEADERBOARD': {'Task': 'Lecture Transcripts', 'Dataset': 'PubMed', 'Metric': 'ROUGE-2', 'Score': '23.28'}}, {'LEADERBOARD': {'Task': 'Lecture Transcripts', 'Dataset': 'PubMed', 'Metric': 'ROUGE-1', 'Score': '50.25'}}]\",\n",
       " \"[{'LEADERBOARD': {'Task': 'LLM Distractor', 'Dataset': 'Distractor', 'Metric': 'Average Test Accuracy', 'Score': ''}}, {'LEADERBOARD': {'Task': 'LLM Number of Digits', 'Dataset': 'Number of Digits', 'Metric': 'Average Test Accuracy', 'Score': ''}}, {'LEADERBOARD': {'Task': 'LLM Reasoning Step', 'Dataset': 'Reasoning Step', 'Metric': 'Average Test Accuracy', 'Score': ''}}, {'LEADERBOARD': {'Task': 'LLM Grade', 'Dataset': 'Grade', 'Metric': 'Average Test Accuracy', 'Score': ''}}]\",\n",
       " \"[ {'Task': 'Classification and Regression', 'Dataset': 'Internal user studies with informed consent approvals', 'Metric': FRR', 'Score': '1.99'}, {'Task': 'Classification and Regression', 'Dataset': 'Internal user studies with informed consent approvals', 'Metric': FRR', 'Score': '1.7'}, {'Task': 'Classification and Regression', 'Dataset': 'Internal user studies with informed consent approvals', 'Metric': FRR', 'Score': '0.45'}]\",\n",
       " \"[{'LEADERBOARD': {'Task': 'BMRC', 'Dataset': 'ASTE-Data-V2', 'Metric': '', 'Score': '53.77'}}, {'LEADERBOARD': {'Task': 'TOP', 'Dataset': 'ASTE-Data-V2', 'Metric': '', 'Score': '55.94'}}, {'LEADERBOARD': {'Task': 'GTS', 'Dataset': 'ASTE-Data-V2', 'Metric': '', 'Score': '62.46'}}, {'LEADERBOARD': {'Task': 'JET', 'Dataset': 'ASTE-Data-V2', 'Metric': '', 'Score': '57.70'}}]\",\n",
       " \"[{'LEADERBOARD': {'Task': 'High resolution spectral analysis', 'Dataset': '', 'Metric': '', 'Score': ''}}, {'LEADERBOARD': {'Task': 'Worst-case Throughput Analysis', 'Dataset': '', 'Metric': 'Throughput', 'Score': ''}}, {'LEADERBOARD': {'Task': 'Fundam. freq. detector based on norm. autocorr.', 'Dataset': '', 'Metric': '', 'Score': ''}}, {'LEADERBOARD': {'Task': 'Adaptive predictor program', 'Dataset': '', 'Metric': '', 'Score': ''}}, {'LEADERBOARD': {'Task': 'Normalized LMS alg.', 'Dataset': '', 'Metric': '', 'Score': ''}}, {'LEADERBOARD': {'Task': 'Bound. block parallel latt. reduct. alg.', 'Dataset': '', 'Metric': '', 'Score': ''}}]\",\n",
       " \"[ {'Task': 'DocRE', 'Dataset': 'DocRED', 'Metric': F1', 'Score': '53.73'}, {'Task': 'DocRE', 'Dataset': 'DocRED', 'Metric': F1', 'Score': '52.46'}, {'Task': 'DocRE', 'Dataset': 'DocRED', 'Metric': F1', 'Score': '51.92'}, {'Task': 'DocRE', 'Dataset': 'HacRED', 'Metric': F1', 'Score': '78.27'}]\",\n",
       " \"[{'LEADERBOARD': {'Task': 'Czech GEC', 'Dataset': '', 'Metric': '', 'Score': '-6.65 points lower than the model by citet{low_resource_gec}'}}, {'LEADERBOARD': {'Task': 'German GEC', 'Dataset': '', 'Metric': '', 'Score': '-4.45 points lower than the model by citet{low_resource_gec}'}}, {'LEADERBOARD': {'Task': 'Russian GEC', 'Dataset': '', 'Metric': '', 'Score': 'much lower scores than citet{low_resource_gec}'s model'}}, {'LEADERBOARD': {'Task': 'English GEC', 'Dataset': 'CoNLL-14 and BEA-test', 'Metric': '', 'Score': 'comparable to current strong results'}}]\",\n",
       " \"[{'LEADERBOARD': {'Task': 'Object Detection', 'Dataset': 'LVIS v1.0', 'Metric': 'AP', 'Score': '41.5'}}, {'LEADERBOARD': {'Task': 'Object Detection', 'Dataset': 'LVIS v1.0', 'Metric': 'AP', 'Score': '41.23'}}]\",\n",
       " \"[{'LEADERBOARD': {'Task': 'PSD Data (MLM-only)', 'Dataset': '', 'Metric': '', 'Score': '64.1'}}, {'LEADERBOARD': {'Task': 'PSD Data (MLM-only)', 'Dataset': '', 'Metric': '', 'Score': '87.1'}}, {'LEADERBOARD': {'Task': 'PSD Data (MLM-only)', 'Dataset': '', 'Metric': '', 'Score': '79.1'}}, {'LEADERBOARD': {'Task': 'SP', 'Dataset': '', 'Metric': '', 'Score': '81.0'}}, {'LEADERBOARD': {'Task': 'PSD Data (MLM-only)', 'Dataset': '', 'Metric': '', 'Score': '67.3'}}, {'LEADERBOARD': {'Task': 'SP', 'Dataset': '', 'Metric': '', 'Score': '90.9'}}, {'LEADERBOARD': {'Task': 'SP', 'Dataset': '', 'Metric': '', 'Score': '74.5'}}, {'LEADERBOARD': {'Task': 'PSD', 'Dataset': '', 'Metric': '', 'Score': '73.7'}}, {'LEADERBOARD': {'Task': 'SP', 'Dataset': '', 'Metric': '', 'Score': '87.7'}}, {'LEADERBOARD': {'Task': 'PSD', 'Dataset': '', 'Metric': '', 'Score': '67.7'}}, {'LEADERBOARD': {'Task': 'SP', 'Dataset': '', 'Metric': '', 'Score': '88.9'}}, {'LEADERBOARD': {'Task': 'PSD Data (MLM-only)', 'Dataset': '', 'Metric': '', 'Score': '85.6'}}, {'LEADERBOARD': {'Task': 'PSD', 'Dataset': '', 'Metric': '', 'Score': '88.0'}}, {'LEADERBOARD': {'Task': 'SP', 'Dataset': '', 'Metric': '', 'Score': '68.3'}}, {'LEADERBOARD': {'Task': 'PSD Data (MLM-only)', 'Dataset': '', 'Metric': '', 'Score': '73.7'}}, {'LEADERBOARD': {'Task': 'PSD', 'Dataset': '', 'Metric': '', 'Score': '80.5'}}, {'LEADERBOARD': {'Task': 'PSD', 'Dataset': '', 'Metric': '', 'Score': '86.4'}}, {'LEADERBOARD': {'Task': 'SP', 'Dataset': '', 'Metric': '', 'Score': '64.1'}}, {'LEADERBOARD': {'Task': 'PSD', 'Dataset': '', 'Metric': '', 'Score': '62.6'}}]\",\n",
       " \"[{'LEADERBOARD': {'Task': 'Textual Cloze Task', 'Dataset': 'RecipeQA', 'Metric': 'p@2', 'Score': '76.3'}}, {'LEADERBOARD': {'Task': 'Textual Cloze Task', 'Dataset': 'RecipeQA', 'Metric': 'p@2', 'Score': '77.5'}}, {'LEADERBOARD': {'Task': 'Textual Cloze Task', 'Dataset': 'RecipeQA', 'Metric': 'Accuracy', 'Score': '46.9'}}, {'LEADERBOARD': {'Task': 'Textual Cloze Task', 'Dataset': 'RecipeQA', 'Metric': 'p@2', 'Score': '78.7'}}, {'LEADERBOARD': {'Task': 'Textual Cloze Task', 'Dataset': 'RecipeQA', 'Metric': 'Accuracy', 'Score': '46.35'}}, {'LEADERBOARD': {'Task': 'Textual Cloze Task', 'Dataset': 'RecipeQA', 'Metric': 'Accuracy', 'Score': '45.41'}}]\",\n",
       " \"[{'LEADERBOARD': {'Task': 'Action Spotting', 'Dataset': 'SoccerNet', 'Metric': 'Average-mAP', 'Score': '65.2'}}, {'LEADERBOARD': {'Task': 'Action Spotting', 'Dataset': 'SoccerNet', 'Metric': 'Average-mAP', 'Score': '63.8'}}, {'LEADERBOARD': {'Task': 'Action Spotting', 'Dataset': 'SoccerNet', 'Metric': 'Average-mAP', 'Score': '62.9'}}, {'LEADERBOARD': {'Task': 'Action Spotting', 'Dataset': 'SoccerNet', 'Metric': 'Average-mAP', 'Score': '61.4'}}, {'LEADERBOARD': {'Task': 'Action Spotting', 'Dataset': 'SoccerNet', 'Metric': 'Average-mAP', 'Score': '75.1'}}, {'LEADERBOARD': {'Task': 'Action Spotting', 'Dataset': 'SoccerNet', 'Metric': 'Average-mAP', 'Score': '54.1'}}, {'LEADERBOARD': {'Task': 'Action Spotting', 'Dataset': 'SoccerNet', 'Metric': 'Average-mAP', 'Score': '64.6'}}, {'LEADERBOARD': {'Task': 'Action Spotting', 'Dataset': 'SoccerNet', 'Metric': 'Average-mAP', 'Score': '77.5'}}, {'LEADERBOARD': {'Task': 'Action Spotting', 'Dataset': 'SoccerNet', 'Metric': 'Average-mAP', 'Score': '62.5'}}]\",\n",
       " \"[{'LEADERBOARD': {'Task': 'boat', 'Dataset': '', 'Metric': 'mAP', 'Score': '51.6'}}, {'LEADERBOARD': {'Task': 'aero', 'Dataset': '', 'Metric': 'mAP', 'Score': '77.8'}}, {'LEADERBOARD': {'Task': 'bird', 'Dataset': '', 'Metric': 'mAP', 'Score': '69.3'}}, {'LEADERBOARD': {'Task': 'cow', 'Dataset': '', 'Metric': 'mAP', 'Score': '82'}}, {'LEADERBOARD': {'Task': 'dog', 'Dataset': '', 'Metric': 'mAP', 'Score': '76.8'}}, {'LEADERBOARD': {'Task': 'bottle', 'Dataset': '', 'Metric': 'mAP', 'Score': '55.3'}}, {'LEADERBOARD': {'Task': 'table', 'Dataset': '', 'Metric': 'mAP', 'Score': '63.6'}}, {'LEADERBOARD': {'Task': 'motor', 'Dataset': '', 'Metric': 'mAP', 'Score': '42.8'}}, {'LEADERBOARD': {'Task': 'cat', 'Dataset': '', 'Metric': 'mAP', 'Score': '80.2'}}, {'LEADERBOARD': {'Task': 'train', 'Dataset': '', 'Metric': 'mAP', 'Score': '67.2'}}, {'LEADERBOARD': {'Task': 'bus', 'Dataset': '', 'Metric': 'mAP', 'Score': '74.5'}}, {'LEADERBOARD': {'Task': 'chair', 'Dataset': '', 'Metric': 'mAP', 'Score': '49.3'}}, {'LEADERBOARD': {'Task': 'bike', 'Dataset': '', 'Metric': 'mAP', 'Score': '74.8'}}, {'LEADERBOARD': {'Task': 'cycle', 'Dataset': '', 'Metric': 'mAP', 'Score': '81.7'}}, {'LEADERBOARD': {'Task': 'horse', 'Dataset': '', 'Metric': 'mAP', 'Score': '80.9'}}, {'LEADERBOARD': {'Task': 'car', 'Dataset': '', 'Metric': 'mAP', 'Score': '86.3'}}, {'LEADERBOARD': {'Task': 'person', 'Dataset': '', 'Metric': 'mAP', 'Score': '75.7'}}, {'LEADERBOARD': {'Task': 'carriage', 'Dataset': '', 'Metric': 'mAP', 'Score': '61.2'}}, {'LEADERBOARD': {'Task': 'truck', 'Dataset': '', 'Metric': 'mAP', 'Score': '74.7'}}]\",\n",
       " \"[{'LEADERBOARD': {'Task': 'Vision-and-Language Navigation', 'Dataset': 'Test (unseen)', 'Metric': 'Navigation Error', 'Score': '7.85'}}, {'LEADERBOARD': {'Task': 'Vision-and-Language Navigation', 'Dataset': 'Val Seen', 'Metric': 'Navigation Error', 'Score': '0.00'}}, {'LEADERBOARD': {'Task': 'Vision-and-Language Navigation', 'Dataset': 'Room-2-Room (R2R)', 'Metric': 'Success Rate', 'Score': '100'}}, {'LEADERBOARD': {'Task': 'Vision-and-Language Navigation', 'Dataset': 'Test (unseen)', 'Metric': 'Success Rate', 'Score': '20.4'}}, {'LEADERBOARD': {'Task': 'Vision-and-Language Navigation', 'Dataset': 'Val Unseen', 'Metric': 'Navigation Error', 'Score': '8.61'}}]\",\n",
       " \"[{'LEADERBOARD': {'Task': 'Parsimonious flooding in dynamic graphs', 'Dataset': 'N/A', 'Metric': 'Flooding time', 'Score': '260--269'}}, {'LEADERBOARD': {'Task': 'Broadcasting in unreliable radio networks', 'Dataset': 'N/A', 'Metric': 'Broadcasting time', 'Score': '336--345'}}, {'LEADERBOARD': {'Task': 'Compact semantic segmentation', 'Dataset': 'CamVid, CityScapes', 'Metric': 'Mean IoU', 'Score': '63.2%, 67.8%'}}, {'LEADERBOARD': {'Task': 'Flooding time in edge-Markovian dynamic graphs', 'Dataset': 'N/A', 'Metric': 'Flooding time', 'Score': 'N/A'}}, {'LEADERBOARD': {'Task': 'Coordinated consensus in dynamic networks', 'Dataset': 'N/A', 'Metric': 'Consensus time', 'Score': '1--10'}}, {'LEADERBOARD': {'Task': 'Optimal gradient clock synchronization in dynamic networks', 'Dataset': 'N/A', 'Metric': 'Clock synchronization', 'Score': '430--439'}}, {'LEADERBOARD': {'Task': 'How to explore a fast-changing world (cover time of a simple random walk on evolving graphs)', 'Dataset': 'N/A', 'Metric': 'Cover time', 'Score': '121--132'}}, {'LEADERBOARD': {'Task': 'Opportunistic information dissemination in mobile ad-hoc networks', 'Dataset': 'N/A', 'Metric': 'Profit of global synchrony', 'Score': '374--388'}}]\",\n",
       " \"[{'LEADERBOARD': {'Task': 'Dominating Set', 'Dataset': '', 'Metric': '', 'Score': 'time'}}]\",\n",
       " 'unanswerable\\n',\n",
       " \"[{'LEADERBOARD': {'Task': 'Image Restoration', 'Dataset': 'GoPro', 'Metric': 'PSNR', 'Score': '30.76'}}, {'LEADERBOARD': {'Task': 'Image Restoration', 'Dataset': 'GoPro', 'Metric': 'PSNR', 'Score': '30.52'}}]\",\n",
       " \"[{'LEADERBOARD': {'Task': 'Template-Based Automatic Search of Compact Semantic Segmentation Architectures', 'Dataset': 'CityScapes', 'Metric': 'mean IoU', 'Score': '67.8'}}, {'LEADERBOARD': {'Task': 'Template-Based Automatic Search of Compact Semantic Segmentation Architectures', 'Dataset': 'CamVid', 'Metric': 'mean IoU', 'Score': '63.2'}}]\",\n",
       " \"[ {'Task': 'Geometric Stabbing', 'Dataset': 'Unit Squares', 'Metric': '', 'Score': 'W[1]-hard'}, {'Task': 'Geometric Stabbing', 'Dataset': 'Disjoint Unit Squares', 'Metric': '', 'Score': 'FPT'}, {'Task': 'Geometric Stabbing', 'Dataset': 'Disjoint Rectangles (Fixed)', 'Metric': '', 'Score': 'FPT'}, {'Task': 'Geometric Stabbing', 'Dataset': 'Disjoint Rectangles (Input)', 'Metric': '', 'Score': 'W[1]-hard'}]Note that the scores are reported as complexity classes (e.g., W[1]\",\n",
       " 'unanswerable\\n',\n",
       " \"[{'LEADERBOARD': {'Task': 'Required Transmitter Power', 'Dataset': '', 'Metric': '', 'Score': ''}}, {'LEADERBOARD': {'Task': 'Power Level for Different Regions', 'Dataset': '', 'Metric': '', 'Score': ''}}, {'LEADERBOARD': {'Task': 'Link Quality and Temperature', 'Dataset': '', 'Metric': '', 'Score': ''}}, {'LEADERBOARD': {'Task': 'Estimated Parameters', 'Dataset': '', 'Metric': '', 'Score': ''}}]\",\n",
       " 'unanswerable\\n',\n",
       " 'unanswerable\\n',\n",
       " \"[{'LEADERBOARD': {'Task': 'Few-shot Learning', 'Dataset': 'Mini-ImageNet', 'Metric': 'Test Accuracy', 'Score': '5-shot'}}, {'LEADERBOARD': {'Task': 'Few-shot Learning', 'Dataset': 'Mini-ImageNet', 'Metric': 'Test Accuracy', 'Score': '1-shot'}}, {'LEADERBOARD': {'Task': 'Few-shot Learning', 'Dataset': 'CUB', 'Metric': 'Test Accuracy', 'Score': '1-shot'}}, {'LEADERBOARD': {'Task': 'Few-shot Learning', 'Dataset': 'CUB', 'Metric': 'Test Accuracy', 'Score': '5-shot'}}]\",\n",
       " \"[Based on the provided text, I can extract the reported tasks, datasets, metrics, and scores as follows:Text: titleSIGACT News Logic Column 18text{ is true if is true textbf{BroccoliSince there is no benchmark leaderboard results in this text, the output will be an empty JSON array.However, I can provide you with a template for future reference. If you provide me with a text that reports benchmark leaderboard results, I'll be happy to help you extract the tasks, datasets, metrics, and scores as reported in the text.Please let me know if there's anything else I can assist you with!]\",\n",
       " \"[{'LEADERBOARD': {'Task': 'Benchmark Leaderboard Results', 'Dataset': '(5, 92.01)', 'Metric': '', 'Score': ''}}, {'LEADERBOARD': {'Task': 'Genia', 'Dataset': '', 'Metric': 'Recall', 'Score': '79.85'}}, {'LEADERBOARD': {'Task': 'Genia', 'Dataset': '', 'Metric': 'Recall', 'Score': '74.72'}}, {'LEADERBOARD': {'Task': 'Genia', 'Dataset': '', 'Metric': 'Recall', 'Score': '77.86'}}, {'LEADERBOARD': {'Task': 'Genia', 'Dataset': '', 'Metric': 'Recall', 'Score': '71.78'}}, {'LEADERBOARD': {'Task': 'Genia', 'Dataset': '', 'Metric': 'Recall', 'Score': '77.57'}}, {'LEADERBOARD': {'Task': 'ShARe14', 'Dataset': '', 'Metric': 'Recall', 'Score': '89.54'}}, {'LEADERBOARD': {'Task': 'ShARe14', 'Dataset': '', 'Metric': 'Recall', 'Score': '84.05'}}, {'LEADERBOARD': {'Task': 'ShARe14', 'Dataset': '', 'Metric': 'Recall', 'Score': '84.03'}}, {'LEADERBOARD': {'Task': 'ShARe14', 'Dataset': '', 'Metric': 'Recall', 'Score': '82.81'}}, {'LEADERBOARD': {'Task': 'ShARe14', 'Dataset': '', 'Metric': 'Recall', 'Score': '85.02'}}, {'LEADERBOARD': {'Task': 'ShARe14', 'Dataset': '', 'Metric': 'Recall', 'Score': '91.38'}}, {'LEADERBOARD': {'Task': 'Genia', 'Dataset': '', 'Metric': 'Recall', 'Score': '78.43'}}]\",\n",
       " \"[{'LEADERBOARD': {'Task': 'Molecular Dynamics of C-Fullerene', 'Dataset': 'C-20', 'Metric': 'Mean Absolute Error (MAE)', 'Score': '0.228 kcal/mol'}}, {'LEADERBOARD': {'Task': 'Potential Energy Surfaces and Force Fields', 'Dataset': 'MD17', 'Metric': 'Mean Absolute Error (MAE)', 'Score': '0.23 kcal/mol'}}, {'LEADERBOARD': {'Task': 'Molecular Dynamics Simulations', 'Dataset': 'MD17', 'Metric': 'Mean Absolute Error (MAE)', 'Score': '0.12 kcal/mol'}}]\",\n",
       " \"[{'LEADERBOARD': {'Task': 'Energy Minimization', 'Dataset': 'Two Holes Mesh', 'Metric': 'Angle Histogram', 'Score': 'Improved'}}, {'LEADERBOARD': {'Task': 'Energy Minimization', 'Dataset': 'Two Holes Mesh', 'Metric': 'Triangle Quality', 'Score': 'Reduced Non-Acute Triangles'}}, {'LEADERBOARD': {'Task': 'Energy Minimization', 'Dataset': 'Two Holes Mesh', 'Metric': 'Angle Distribution', 'Score': 'Improved Standard Deviation'}}]\",\n",
       " \"[{'LEADERBOARD': {'Task': 'Reconstruction', 'Dataset': 'AXYZ', 'Metric': 'Chamfer', 'Score': '0.89'}}, {'LEADERBOARD': {'Task': 'Reconstruction', 'Dataset': 'AXYZ', 'Metric': 'Normal', 'Score': '0.042'}}, {'LEADERBOARD': {'Task': 'Reconstruction', 'Dataset': 'AXYZ', 'Metric': 'Chamfer', 'Score': '0.91'}}, {'LEADERBOARD': {'Task': 'Reconstruction', 'Dataset': 'AXYZ', 'Metric': 'P2S', 'Score': '0.75'}}, {'LEADERBOARD': {'Task': 'Reconstruction', 'Dataset': 'AXYZ', 'Metric': 'P2S', 'Score': '0.76'}}, {'LEADERBOARD': {'Task': 'Reconstruction', 'Dataset': 'AXYZ', 'Metric': 'P2S', 'Score': '0.74'}}, {'LEADERBOARD': {'Task': 'Reconstruction', 'Dataset': 'AXYZ', 'Metric': 'Normal', 'Score': '0.043'}}, {'LEADERBOARD': {'Task': 'Reconstruction', 'Dataset': 'AXYZ', 'Metric': 'Chamfer', 'Score': '0.85'}}, {'LEADERBOARD': {'Task': 'Reconstruction', 'Dataset': 'AXYZ', 'Metric': 'Normal', 'Score': '0.045'}}]\",\n",
       " \"[{'LEADERBOARD': {'Task': 'Wildcard Copying and Adding', 'Dataset': 'Matching Copies for Remaining Symbols', 'Metric': 'Score', 'Score': 'there are matching copies for the remaining symbols'}}, {'LEADERBOARD': {'Task': 'Benchmark Leaderboard Results', 'Dataset': 'Wildcard Symbol', 'Metric': 'Score', 'Score': 'There exists some wildcard symbol in the encoding of the current configuration'}}, {'LEADERBOARD': {'Task': 'Wildcard Replacement', 'Dataset': 'Two Time Units Later', 'Metric': 'Score', 'Score': 'the first wildcard symbol is replaced by two time units later'}}]\",\n",
       " \"[{'LEADERBOARD': {'Task': 'Transfer Learning', 'Dataset': 'OGB', 'Metric': '', 'Score': ''}}, {'LEADERBOARD': {'Task': 'Node Classification', 'Dataset': '100K', 'Metric': '', 'Score': '90.705'}}, {'LEADERBOARD': {'Task': 'Graph Classification/Regression', 'Dataset': 'MNIST', 'Metric': '', 'Score': ''}}, {'LEADERBOARD': {'Task': 'Graph Classification/Regression', 'Dataset': 'ZINC', 'Metric': '', 'Score': ''}}, {'LEADERBOARD': {'Task': 'Graph Classification/Regression', 'Dataset': 'CIFAR10', 'Metric': '', 'Score': ''}}, {'LEADERBOARD': {'Task': 'Graph Regression', 'Dataset': 'PCQM4Mv2', 'Metric': '', 'Score': '86.816'}}, {'LEADERBOARD': {'Task': 'Node Classification', 'Dataset': '500K', 'Metric': '', 'Score': '71.892'}}, {'LEADERBOARD': {'Task': 'Edge Classification', 'Dataset': 'TSP', 'Metric': '', 'Score': '68.702'}}, {'LEADERBOARD': {'Task': 'Node Classification', 'Dataset': 'PATTERN', 'Metric': '', 'Score': '63.880'}}]\",\n",
       " \"[{'LEADERBOARD': {'Task': 'Multi-Party Multi-Turn Dialogue MRC', 'Dataset': 'FriendsQA', 'Metric': 'F1 score', 'Score': '64.4'}}, {'LEADERBOARD': {'Task': 'Multi-Party Multi-Turn Dialogue MRC', 'Dataset': 'Molweni', 'Metric': 'F1 score', 'Score': '49.7'}}]\",\n",
       " \"[{'LEADERBOARD': {'Task': 'Backtracking Algorithm Comparison', 'Dataset': 'Hard instances', 'Metric': 'Runtime', 'Score': 'various'}}, {'LEADERBOARD': {'Task': 'Service Selection Problem', 'Dataset': 'Pegasus database', 'Metric': 'Runtime', 'Score': 'seconds'}}, {'LEADERBOARD': {'Task': 'Service Selection Problem', 'Dataset': 'Genelife2 workflow', 'Metric': 'Runtime', 'Score': 'operations nodes'}}, {'LEADERBOARD': {'Task': 'Service Selection Problem', 'Dataset': 'Motif network', 'Metric': 'Runtime', 'Score': 'operations nodes'}}]\",\n",
       " \"[{'LEADERBOARD': {'Task': 'Scenario and Action Prediction', 'Dataset': 'Multi', 'Metric': '', 'Score': '79.70'}}, {'LEADERBOARD': {'Task': 'Scenario and Action Prediction', 'Dataset': 'Gold', 'Metric': '', 'Score': '90.15'}}, {'LEADERBOARD': {'Task': 'Entity Prediction', 'Dataset': 'Multi', 'Metric': 'F1', 'Score': '62.69'}}, {'LEADERBOARD': {'Task': 'Scenario and Action Prediction', 'Dataset': 'Multi', 'Metric': '', 'Score': '83.73'}}, {'LEADERBOARD': {'Task': 'Scenario and Action Prediction', 'Dataset': 'Gold', 'Metric': '', 'Score': '86.99'}}, {'LEADERBOARD': {'Task': 'Scenario and Action Prediction', 'Dataset': 'SLURP', 'Metric': '', 'Score': '82.31'}}, {'LEADERBOARD': {'Task': 'Scenario and Action Prediction', 'Dataset': 'Gold', 'Metric': '', 'Score': '84.84'}}, {'LEADERBOARD': {'Task': 'Entity Prediction', 'Dataset': 'SLURP', 'Metric': 'F1', 'Score': '59.79'}}, {'LEADERBOARD': {'Task': 'Entity Prediction', 'Dataset': 'Gold', 'Metric': 'F1', 'Score': '78.19'}}, {'LEADERBOARD': {'Task': 'Scenario and Action Prediction', 'Dataset': 'Google', 'Metric': '', 'Score': '81.68'}}]\",\n",
       " \"[{'LEADERBOARD': {'Task': 'Reconstructing Curves from Points and Tangents', 'Dataset': '', 'Metric': '', 'Score': ''}}]\",\n",
       " \"[{'LEADERBOARD': {'Task': 'SceneNN', 'Dataset': '', 'Metric': 'RMSE (correctly aligned pairs)', 'Score': '4.68 cm'}}, {'LEADERBOARD': {'Task': 'SceneNN', 'Dataset': '', 'Metric': 'RMSE', 'Score': '11.83 cm'}}, {'LEADERBOARD': {'Task': 'SceneNN', 'Dataset': '', 'Metric': 'RMSE (correctly aligned pairs)', 'Score': '4.07 cm'}}, {'LEADERBOARD': {'Task': 'SceneNN', 'Dataset': '', 'Metric': 'RMSE', 'Score': '14.86 cm'}}]\",\n",
       " \"[{'LEADERBOARD': {'Task': 'RL significantly improves few-shot performance, but provides more modest gains on top of SFT.', 'Dataset': 'Few-shot and SFT settings', 'Metric': 'Final-Answer Error Rate', 'Score': 'half'}}, {'LEADERBOARD': {'Task': 'OOD generalization', 'Dataset': 'MATH dataset (pre-algebra split)', 'Metric': 'Final-Answer Error Rate', 'Score': '64.6%'}}, {'LEADERBOARD': {'Task': 'Optimizing against an RM outperforms optimizing final-answer correctness directly.', 'Dataset': 'Few-shot and SFT settings', 'Metric': 'Final-Answer Error Rate', 'Score': 'outperforms'}}, {'LEADERBOARD': {'Task': 'Selective prediction greatly reduces final-answer error, particularly for models with low trace error.', 'Dataset': 'SFT setting', 'Metric': 'Selective Error Rate', 'Score': '5 reduction factor'}}]\",\n",
       " \"[{'LEADERBOARD': {'Task': 'PACS results with deep residual network architectures', 'Dataset': 'ResNet-18, ResNet-50', 'Metric': '', 'Score': ''}}, {'LEADERBOARD': {'Task': 'Tissue Segmentation in Multi-site Brain MRI', 'Dataset': '', 'Metric': '', 'Score': ''}}, {'LEADERBOARD': {'Task': 'PACS results with deep residual network architectures', 'Dataset': 'Art-painting, Cartoon, Photo, Sketch', 'Metric': 'Accuracy', 'Score': '77.38, 80.29, 94.25, 69.64'}}]\",\n",
       " 'unanswerable\\n',\n",
       " \"[{'LEADERBOARD': {'Task': 'Real-World Applications', 'Dataset': 'APC', 'Metric': 'FID scores for generated images', 'Score': 'outperformed by Genesis'}}, {'LEADERBOARD': {'Task': 'Real-World Applications', 'Dataset': 'Sketchy', 'Metric': 'ARI and MSC scores', 'Score': 'stand out'}}, {'LEADERBOARD': {'Task': 'Real-World Applications', 'Dataset': 'Sketchy', 'Metric': 'FID scores for generated images', 'Score': 'best FID'}}, {'LEADERBOARD': {'Task': 'Real-World Applications', 'Dataset': 'APC', 'Metric': 'ARI and MSC scores', 'Score': 'stands out'}}]\",\n",
       " \"[{'LEADERBOARD': {'Task': 'Template-Based Automatic Search of Compact Semantic Segmentation Architectures', 'Dataset': 'CityScapes', 'Metric': 'mean IoU', 'Score': '67.8'}}, {'LEADERBOARD': {'Task': 'Template-Based Automatic Search of Compact Semantic Segmentation Architectures', 'Dataset': 'CamVid', 'Metric': 'mean IoU', 'Score': '63.2'}}]\",\n",
       " \"[{'LEADERBOARD': {'Task': 'Super-Resolution', 'Dataset': 'Four benchmark datasets', 'Metric': 'IFC', 'Score': 'best performance'}}, {'LEADERBOARD': {'Task': 'Image Super-Resolution', 'Dataset': '8023', 'Metric': 'Visual comparison', 'Score': 'clearer contour without serious artifacts'}}, {'LEADERBOARD': {'Task': 'Image Super-Resolution', 'Dataset': 'Barbara', 'Metric': 'Visual comparison', 'Score': 'clearer contour without serious artifacts'}}, {'LEADERBOARD': {'Task': 'Super-Resolution', 'Dataset': 'Benchmark datasets', 'Metric': 'PSNR and SSIM', 'Score': 'state-of-the-art results'}}, {'LEADERBOARD': {'Task': 'Image Super-Resolution', 'Dataset': 'img085', 'Metric': 'Visual comparison', 'Score': 'relatively clear building structure'}}]\",\n",
       " 'unanswerable\\n',\n",
       " \"[{'LEADERBOARD': {'Task': 'Comparison on CIFAR-100-LT', 'Dataset': 'CIFAR-100-LT', 'Metric': 'Top-1 accuracy', 'Score': '-'}}, {'LEADERBOARD': {'Task': 'Comparison on iNaturalist 2018', 'Dataset': 'iNaturalist 2018', 'Metric': 'Top-1 accuracy', 'Score': '73.2'}}, {'LEADERBOARD': {'Task': 'Comparison on iNaturalist 2018', 'Dataset': 'iNaturalist 2018', 'Metric': 'Top-1 accuracy', 'Score': '75.3'}}]\",\n",
       " \"[ {'Task': 'Optical Flow Estimation', 'Dataset': 'Sintel', 'Metric': '', 'Score': '9.32'}, {'Task': 'Optical Flow Estimation', 'Dataset': 'DAVIS', 'Metric': '', 'Score': ''}, {'Task': 'Optical Flow Estimation', 'Dataset': 'KITTI', 'Metric': 'F1-all', 'Score': '11.48 (All), 6.94 (Noc)'},]\",\n",
       " 'unanswerable\\n',\n",
       " 'unanswerable\\n',\n",
       " \"[ {'Task': 'KL Divergence', 'Dataset': 'Two-spiral Gaussian Mixture', 'Metric': KL Divergence', 'Score': 0.1246}, {'Task': 'KL Divergence', 'Dataset': 'Two-spiral Gaussian Mixture', 'Metric': KL Divergence, 'Score': 0.1147}, {'Task': 'KL Divergence', 'Dataset': 'Two-spiral Gaussian Mixture', 'Metric': KL Divergence, 'Score': 0.1036}, {'Task': 'KL Divergence', 'Dataset': 'Two-spiral Gaussian Mixture', 'Metric': KL Divergence, 'Score': 0.0857}, {'Task': 'KL Divergence', 'Dataset': 'Two-spiral Gaussian Mixture', 'Metric': KL Divergence, 'Score': 0.1365}, {'Task': 'KL Divergence', 'Dataset': 'Two-spiral Gaussian Mixture', 'Metric': KL Divergence, 'Score': 0.1686}]\",\n",
       " 'unanswerable\\n',\n",
       " 'unanswerable\\n',\n",
       " \"[ {'Task': 'Domain Adaptation', 'Dataset': 'VOC (labeled source domain)', 'Metric': mAP', 'Score': '40.4'}, {'Task': 'Domain Adaptation', 'Dataset': 'Clipart, Watercolor, Comic', 'Metric': mAP', 'Score': '49.7'}, {'Task': 'Domain Adaptation', 'Dataset': 'Comic', 'Metric': mAP', 'Score': '46.3'}]\",\n",
       " 'unanswerable\\n',\n",
       " 'unanswerable\\n',\n",
       " \"[{'LEADERBOARD': {'Task': 'Destination Localization', 'Dataset': 'Nexus 4 #1', 'Metric': '% of scenarios with accurate final destination estimates', 'Score': '80'}}, {'LEADERBOARD': {'Task': 'Full Route Estimation', 'Dataset': 'Nexus 4 #1', 'Metric': '% of full route estimated accurately', 'Score': '45'}}, {'LEADERBOARD': {'Task': 'Full Route Estimation', 'Dataset': 'Nexus 4 #2', 'Metric': '% of full route estimated accurately', 'Score': '15'}}, {'LEADERBOARD': {'Task': 'Full Route Estimation', 'Dataset': 'HTC Desire', 'Metric': '% of full route estimated accurately', 'Score': '17'}}, {'LEADERBOARD': {'Task': 'Destination Localization', 'Dataset': 'HTC Desire', 'Metric': '% of scenarios with accurate final destination estimates', 'Score': '55'}}, {'LEADERBOARD': {'Task': 'Full Route Estimation', 'Dataset': 'Nexus 5', 'Metric': '% of full route estimated accurately', 'Score': '20'}}, {'LEADERBOARD': {'Task': 'Destination Localization', 'Dataset': 'Nexus 5', 'Metric': '% of scenarios with accurate final destination estimates', 'Score': '65'}}, {'LEADERBOARD': {'Task': 'Destination Localization', 'Dataset': 'Nexus 4 #2', 'Metric': '% of scenarios with accurate final destination estimates', 'Score': '72'}}]\",\n",
       " \"[{'LEADERBOARD': {'Task': 'Reasoning Tasks in Video QA', 'Dataset': 'SUTD-TrafficQA', 'Metric': 'Accuracy', 'Score': '95.43'}}, {'LEADERBOARD': {'Task': 'Reasoning Tasks in Video QA', 'Dataset': 'SUTD-TrafficQA', 'Metric': 'Accuracy', 'Score': '96.78'}}]\",\n",
       " \"[{'LEADERBOARD': {'Task': 'Dense Polynomial Multiplication', 'Dataset': '', 'Metric': 'Performance', 'Score': 'Sizeable Constant Improvement'}}]\",\n",
       " 'unanswerable\\n',\n",
       " \"[{'LEADERBOARD': {'Task': 'I2I translation', 'Dataset': 'weakly constrained task', 'Metric': '', 'Score': ''}}, {'LEADERBOARD': {'Task': 'I2I translation', 'Dataset': 'strongly constrained task', 'Metric': '', 'Score': ''}}, {'LEADERBOARD': {'Task': 'I2I translation', 'Dataset': 'normally constrained task', 'Metric': '', 'Score': ''}}]\",\n",
       " \"[{'LEADERBOARD': {'Task': 'Model-checking for logics with team semantics', 'Dataset': 'Dependence, Inclusion, and Independence Logic Formulas', 'Metric': 'Data Complexity', 'Score': 'PTIME'}}, {'LEADERBOARD': {'Task': 'Inclusion Logic under Lax Semantics', 'Dataset': 'Dual-Horn Boolean Formulas', 'Metric': 'Satisfiability Problem', 'Score': 'Reduction'}}]\",\n",
       " \"[{'LEADERBOARD': {'Task': 'Keypoint Detection', 'Dataset': 'COCO test-dev', 'Metric': 'AR', 'Score': '71'}}, {'LEADERBOARD': {'Task': 'Person Segmentation', 'Dataset': 'PASCAL VOC 2012 test set', 'Metric': 'IoU', 'Score': '92.1'}}, {'LEADERBOARD': {'Task': 'Person Segmentation', 'Dataset': 'PASCAL VOC 2012 test set', 'Metric': 'IoU', 'Score': '87.8'}}, {'LEADERBOARD': {'Task': 'Keypoint Detection', 'Dataset': 'COCO test-dev', 'Metric': 'AP', 'Score': '81.5'}}]\",\n",
       " \"[{'LEADERBOARD': {'Task': 'SIFT (radius)', 'Dataset': 'aero', 'Metric': '', 'Score': '37'}}, {'LEADERBOARD': {'Task': 'SIFT (radius)', 'Dataset': 'car', 'Metric': '', 'Score': '47'}}, {'LEADERBOARD': {'Task': 'SIFT (radius)', 'Dataset': 'horse', 'Metric': '', 'Score': '42'}}, {'LEADERBOARD': {'Task': 'SIFT (radius)', 'Dataset': 'bike', 'Metric': '', 'Score': '54'}}, {'LEADERBOARD': {'Task': 'convolutional neural network', 'Dataset': 'cat', 'Metric': '', 'Score': '55'}}, {'LEADERBOARD': {'Task': 'SIFT (radius)', 'Dataset': 'train', 'Metric': '', 'Score': '76'}}, {'LEADERBOARD': {'Task': 'SIFT (radius)', 'Dataset': 'table', 'Metric': '', 'Score': '68'}}, {'LEADERBOARD': {'Task': 'SIFT (radius)', 'Dataset': 'bird', 'Metric': '', 'Score': '76'}}, {'LEADERBOARD': {'Task': 'convolutional neural network', 'Dataset': 'train', 'Metric': '', 'Score': '73'}}, {'LEADERBOARD': {'Task': 'convolutional neural network', 'Dataset': 'dog', 'Metric': '', 'Score': '51'}}, {'LEADERBOARD': {'Task': 'SIFT (radius)', 'Dataset': 'prsn', 'Metric': '', 'Score': '70'}}, {'LEADERBOARD': {'Task': 'SIFT (radius)', 'Dataset': 'bus', 'Metric': '', 'Score': '68'}}, {'LEADERBOARD': {'Task': 'convolutional neural network', 'Dataset': 'horse', 'Metric': '', 'Score': '51'}}, {'LEADERBOARD': {'Task': 'SIFT (radius)', 'Dataset': 'dog', 'Metric': '', 'Score': '38'}}, {'LEADERBOARD': {'Task': 'convolutional neural network', 'Dataset': 'car', 'Metric': '', 'Score': '45'}}, {'LEADERBOARD': {'Task': 'convolutional neural network', 'Dataset': 'prsn', 'Metric': '', 'Score': '76'}}, {'LEADERBOARD': {'Task': 'SIFT (radius)', 'Dataset': 'bttl', 'Metric': '', 'Score': '70'}}, {'LEADERBOARD': {'Task': 'convolutional neural network', 'Dataset': 'table', 'Metric': '', 'Score': '68'}}, {'LEADERBOARD': {'Task': 'convolutional neural network', 'Dataset': 'cow', 'Metric': '', 'Score': '48'}}, {'LEADERBOARD': {'Task': 'convolutional neural network', 'Dataset': 'bttl', 'Metric': '', 'Score': '78'}}, {'LEADERBOARD': {'Task': 'convolutional neural network', 'Dataset': 'bird', 'Metric': '', 'Score': '49'}}, {'LEADERBOARD': {'Task': 'convolutional neural network', 'Dataset': 'mbike', 'Metric': '', 'Score': '53'}}, {'LEADERBOARD': {'Task': 'convolutional neural network', 'Dataset': 'bike', 'Metric': '', 'Score': '53'}}, {'LEADERBOARD': {'Task': 'SIFT (radius)', 'Dataset': 'chair', 'Metric': '', 'Score': '43'}}, {'LEADERBOARD': {'Task': 'SIFT (radius)', 'Dataset': 'cat', 'Metric': '', 'Score': '40'}}, {'LEADERBOARD': {'Task': 'convolutional neural network', 'Dataset': 'bus', 'Metric': '', 'Score': '70'}}, {'LEADERBOARD': {'Task': 'SIFT (radius)', 'Dataset': 'boat', 'Metric': '', 'Score': '68'}}, {'LEADERBOARD': {'Task': 'SIFT (radius)', 'Dataset': 'mbike', 'Metric': '', 'Score': '51'}}, {'LEADERBOARD': {'Task': 'convolutional neural network', 'Dataset': 'chair', 'Metric': '', 'Score': '41'}}, {'LEADERBOARD': {'Task': 'SIFT (radius)', 'Dataset': 'cow', 'Metric': '', 'Score': '70'}}, {'LEADERBOARD': {'Task': 'convolutional neural network', 'Dataset': 'aero', 'Metric': '', 'Score': '44'}}, {'LEADERBOARD': {'Task': 'convolutional neural network', 'Dataset': 'boat', 'Metric': '', 'Score': '42'}}]\",\n",
       " 'unanswerable\\n',\n",
       " \"[{'LEADERBOARD': {'Task': 'Template-Based Automatic Search of Compact Semantic Segmentation Architectures', 'Dataset': 'CityScapes', 'Metric': 'mean IoU', 'Score': '67.8'}}, {'LEADERBOARD': {'Task': 'Template-Based Automatic Search of Compact Semantic Segmentation Architectures', 'Dataset': 'CamVid', 'Metric': 'mean IoU', 'Score': '63.2'}}]\",\n",
       " \"[{'LEADERBOARD': {'Task': 'Alternating Automata', 'Dataset': '', 'Metric': '', 'Score': ''}}, {'LEADERBOARD': {'Task': 'Benchmark Leaderboard Results', 'Dataset': '', 'Metric': '', 'Score': ''}}]\",\n",
       " \"[{'LEADERBOARD': {'Task': 'Template-Based Automatic Search of Compact Semantic Segmentation Architectures', 'Dataset': 'CityScapes', 'Metric': 'mean IoU', 'Score': '67.8'}}, {'LEADERBOARD': {'Task': 'Template-Based Automatic Search of Compact Semantic Segmentation Architectures', 'Dataset': 'CamVid', 'Metric': 'mean IoU', 'Score': '63.2'}}]\",\n",
       " \"[{'LEADERBOARD': {'Task': 'Scene Detection', 'Dataset': 'Scene 2', 'Metric': 'Detection', 'Score': '50.0'}}, {'LEADERBOARD': {'Task': 'Scene Detection', 'Dataset': 'Scene 3', 'Metric': 'Detection', 'Score': '74.0'}}, {'LEADERBOARD': {'Task': 'Centerline Estimation', 'Dataset': 'Scene 3', 'Metric': 'C-IOU', 'Score': '59.4'}}, {'LEADERBOARD': {'Task': 'Centerline Estimation', 'Dataset': 'Scene 2', 'Metric': 'C-IOU', 'Score': '27.3'}}]\",\n",
       " \"[{'LEADERBOARD': {'Task': 'WebRTC', 'Dataset': '', 'Metric': 'RTT (ms)', 'Score': '2.22'}}, {'LEADERBOARD': {'Task': 'WebRTC', 'Dataset': '', 'Metric': 'FR (FPS)', 'Score': '21.34'}}, {'LEADERBOARD': {'Task': 'WebRTC', 'Dataset': '', 'Metric': 'BW (kb/s)', 'Score': '4025.30'}}, {'LEADERBOARD': {'Task': 'WebRTC', 'Dataset': '', 'Metric': 'FR (FPS)', 'Score': '30.00'}}, {'LEADERBOARD': {'Task': 'WebRTC', 'Dataset': '', 'Metric': 'FR (FPS)', 'Score': '29.58'}}, {'LEADERBOARD': {'Task': 'WebRTC', 'Dataset': '', 'Metric': 'RTT (ms)', 'Score': '4.22'}}, {'LEADERBOARD': {'Task': 'WebRTC', 'Dataset': '', 'Metric': 'FR (FPS)', 'Score': '29.98'}}, {'LEADERBOARD': {'Task': 'WebRTC', 'Dataset': '', 'Metric': 'BW (kb/s)', 'Score': '4019.16'}}, {'LEADERBOARD': {'Task': 'WebRTC', 'Dataset': '', 'Metric': 'RTT (ms)', 'Score': '17.20'}}, {'LEADERBOARD': {'Task': 'WebRTC', 'Dataset': '', 'Metric': 'RTT (ms)', 'Score': '2.24'}}, {'LEADERBOARD': {'Task': 'WebRTC', 'Dataset': '', 'Metric': 'BW (kb/s)', 'Score': '2229.10'}}, {'LEADERBOARD': {'Task': 'WebRTC', 'Dataset': '', 'Metric': 'BW (kb/s)', 'Score': '2917.85'}}]\",\n",
       " \"[{'LEADERBOARD': {'Task': 'Benchmark Leaderboard Results', 'Dataset': '', 'Metric': 'LSD', 'Score': '1.89'}}, {'LEADERBOARD': {'Task': 'Benchmark Leaderboard Results', 'Dataset': 'Groundtruth-mel', 'Metric': 'LSD', 'Score': '0.76'}}, {'LEADERBOARD': {'Task': 'Benchmark Leaderboard Results', 'Dataset': '', 'Metric': 'LSD', 'Score': '0.86'}}, {'LEADERBOARD': {'Task': 'Benchmark Leaderboard Results', 'Dataset': '', 'Metric': 'LSD', 'Score': '1.04'}}, {'LEADERBOARD': {'Task': 'Benchmark Leaderboard Results', 'Dataset': '', 'Metric': 'LSD', 'Score': '0.84'}}, {'LEADERBOARD': {'Task': 'Benchmark Leaderboard Results', 'Dataset': '', 'Metric': 'LSD', 'Score': '0.98'}}]\",\n",
       " 'unanswerable\\n',\n",
       " \"[{'LEADERBOARD': {'Task': 'MNLI-m', 'Dataset': 'WebSRC', 'Metric': '', 'Score': '57.5'}}, {'LEADERBOARD': {'Task': 'FUNSD', 'Dataset': '', 'Metric': '', 'Score': '86.4'}}, {'LEADERBOARD': {'Task': 'FUNSD', 'Dataset': 'WebSRC', 'Metric': '', 'Score': ''}}, {'LEADERBOARD': {'Task': 'MNLI-m', 'Dataset': '', 'Metric': '', 'Score': '86.2'}}, {'LEADERBOARD': {'Task': '', 'Dataset': '39M', 'Metric': 'Parameter efficiency', 'Score': '146M'}}]\",\n",
       " \"[{'LEADERBOARD': {'Task': 'Image Classification', 'Dataset': 'ImageNet-1K', 'Metric': 'Zero-Shot', 'Score': '75.3'}}, {'LEADERBOARD': {'Task': 'Image Classification', 'Dataset': 'ImageNet-1K', 'Metric': 'Zero-Shot', 'Score': '78.5'}}, {'LEADERBOARD': {'Task': 'Image Classification', 'Dataset': 'ImageNet-1K', 'Metric': 'Zero-Shot', 'Score': '77.6'}}, {'LEADERBOARD': {'Task': 'Image Classification', 'Dataset': 'ImageNet-1K', 'Metric': 'Zero-Shot', 'Score': '66.4'}}, {'LEADERBOARD': {'Task': 'Image Classification', 'Dataset': 'ImageNet-1K', 'Metric': 'Zero-Shot', 'Score': '63.2'}}, {'LEADERBOARD': {'Task': 'Image Classification', 'Dataset': 'ImageNet-1K', 'Metric': 'Zero-Shot', 'Score': '78.1'}}, {'LEADERBOARD': {'Task': 'Image Classification', 'Dataset': 'ImageNet-1K', 'Metric': 'Zero-Shot', 'Score': '68.6'}}]\",\n",
       " \"[ {'Task': 'Find metric index with the largest distance between achieved and assigned score', 'Dataset': '', 'Metric': '', 'Score': ''}, {'Task': 'Train to minimize the loss from', 'Dataset': '', 'Metric': '', 'Score': ''}, {'Task': 'Train all to minimize the distance from', 'Dataset': '', 'Metric': '', 'Score': ''}, {'Task': 'Multi-Metric Scores Assignment', 'Dataset': '', 'Metric': PESQ, 'Score': 2.86}, {'Task': 'Multi-Metric Scores Assignment', 'Dataset': '', 'Metric': CSIG, 'Score': 3.99}, {'Task': 'Multi-Metric Scores Assignment', 'Dataset': '', 'Metric': CBAK, 'Score': 3.18}, {'Task': 'Multi-Metric Scores Assignment', 'Dataset': '', 'Metric': COVL, 'Score': 3.42}, {'Task': 'Comparison with Other State-of-the-Art SE Models', 'Dataset': Publicly available dataset released by [valentini2016investigating], 'Metric': PESQ, 'Score': 2.86}, {'Task': 'Comparison with Other State-of-the-Art SE Models', 'Dataset': Publicly available dataset released by [valentini2016investigating], 'Metric': CSIG, 'Score': 3.99}, {'Task': 'Comparison with Other State-of-the-Art SE Models', 'Dataset': Publicly available dataset released by [valentini2016investigating], 'Metric': CBAK, 'Score': 3.18}, {'Task': 'Comparison with Other State-of-the-Art SE Models', 'Dataset': Publicly available dataset released by [valentini2016investigating], 'Metric': COVL, 'Score': 3.42}]\",\n",
       " \"[{'LEADERBOARD': {'Task': 'Image Reconstruction', 'Dataset': 'Spiral Trajectory Images', 'Metric': 'Times (sec/slice)', 'Score': '0.1431'}}, {'LEADERBOARD': {'Task': 'Image Reconstruction', 'Dataset': 'Radial Trajectory Images', 'Metric': 'SSIM', 'Score': '0.9940'}}, {'LEADERBOARD': {'Task': 'Image Reconstruction', 'Dataset': 'Radial Trajectory Images', 'Metric': 'PSNR', 'Score': '53.5643'}}, {'LEADERBOARD': {'Task': 'Image Reconstruction', 'Dataset': 'Spiral Trajectory Images', 'Metric': 'NMSE', 'Score': '0.0201'}}]\",\n",
       " \"[{'LEADERBOARD': {'Task': 'Template-Based Automatic Search of Compact Semantic Segmentation Architectures', 'Dataset': 'CityScapes', 'Metric': 'mean IoU', 'Score': '67.8'}}, {'LEADERBOARD': {'Task': 'Template-Based Automatic Search of Compact Semantic Segmentation Architectures', 'Dataset': 'CamVid', 'Metric': 'mean IoU', 'Score': '63.2'}}]\",\n",
       " \"[{'LEADERBOARD': {'Task': 'Language Modeling', 'Dataset': 'WikiText-2', 'Metric': 'Perplexity', 'Score': ''}}, {'LEADERBOARD': {'Task': 'Language Modeling', 'Dataset': 'PTB', 'Metric': 'Perplexity', 'Score': '39.97'}}, {'LEADERBOARD': {'Task': 'Language Modeling', 'Dataset': 'WikiText-103', 'Metric': 'Perplexity', 'Score': ''}}, {'LEADERBOARD': {'Task': 'Language Modeling', 'Dataset': 'PTB', 'Metric': 'Validation Perplexity', 'Score': '39.97'}}, {'LEADERBOARD': {'Task': 'Language Modeling', 'Dataset': 'PTB', 'Metric': 'Test Perplexity', 'Score': '34.47'}}]\",\n",
       " \"[{'LEADERBOARD': {'Task': 'Prediction- based NAS', 'Dataset': 'CIFAR-10, CIFAR-100, ImageNet16-120', 'Metric': 'Test-Accuracy', 'Score': '96.6%, 78.8%, 80.1%'}}, {'LEADERBOARD': {'Task': 'Prediction- based NAS', 'Dataset': 'NAS-Bench-201', 'Metric': 'Kendall-Tau, Spearman', 'Score': '0.749, 0.904'}}]\",\n",
       " \"[{'LEADERBOARD': {'Task': 'Evaluation of ErouVe algorithm', 'Dataset': 'Table~ref{params}', 'Metric': 'Vulnerability exploitation', 'Score': ''}}, {'LEADERBOARD': {'Task': 'Evaluation of ErouVe algorithm', 'Dataset': 'Simulation Map', 'Metric': 'Attack success rate', 'Score': ''}}]\",\n",
       " \"[{'LEADERBOARD': {'Task': 'Template-Based Automatic Search of Compact Semantic Segmentation Architectures', 'Dataset': 'CityScapes', 'Metric': 'mean IoU', 'Score': '67.8'}}, {'LEADERBOARD': {'Task': 'Template-Based Automatic Search of Compact Semantic Segmentation Architectures', 'Dataset': 'CamVid', 'Metric': 'mean IoU', 'Score': '63.2'}}]\",\n",
       " \"[{'LEADERBOARD': {'Task': 'ST', 'Dataset': 'MuST-C', 'Metric': 'BLEU', 'Score': ''}}, {'LEADERBOARD': {'Task': 'ASR', 'Dataset': 'LibriSpeech', 'Metric': 'WER', 'Score': '11.4'}}, {'LEADERBOARD': {'Task': 'ASR', 'Dataset': 'LibriSpeech', 'Metric': 'WER', 'Score': '3.2'}}, {'LEADERBOARD': {'Task': 'ST', 'Dataset': 'CoVoST 2', 'Metric': '', 'Score': ''}}, {'LEADERBOARD': {'Task': 'ASR', 'Dataset': 'LibriSpeech', 'Metric': 'WER', 'Score': '8.9'}}, {'LEADERBOARD': {'Task': 'ASR', 'Dataset': 'LibriSpeech', 'Metric': 'WER', 'Score': '3.8'}}, {'LEADERBOARD': {'Task': 'ASR', 'Dataset': 'LibriSpeech', 'Metric': 'WER', 'Score': '3.7'}}, {'LEADERBOARD': {'Task': 'ASR', 'Dataset': 'LibriSpeech', 'Metric': 'WER', 'Score': '7.5'}}]\",\n",
       " \"[{'LEADERBOARD': {'Task': 'Monocular Human Pose Estimation', 'Dataset': 'MPII', 'Metric': 'All PCK', 'Score': '85.0'}}, {'LEADERBOARD': {'Task': 'Monocular Human Pose Estimation', 'Dataset': 'MPII', 'Metric': 'All PCK', 'Score': '79.3'}}, {'LEADERBOARD': {'Task': 'Monocular Human Pose Estimation', 'Dataset': 'MPI-INF-3DHP (indoor)', 'Metric': 'PCK', 'Score': '68.9'}}, {'LEADERBOARD': {'Task': 'Monocular Human Pose Estimation', 'Dataset': 'MPI-INF-3DHP (outdoor)', 'Metric': 'PCK', 'Score': '59.6'}}, {'LEADERBOARD': {'Task': 'Monocular Human Pose Estimation', 'Dataset': 'MPI-INF-3DHP', 'Metric': 'PCK', 'Score': '72.5'}}]\",\n",
       " \"[{'LEADERBOARD': {'Task': 'Template-Based Automatic Search of Compact Semantic Segmentation Architectures', 'Dataset': 'CityScapes', 'Metric': 'mean IoU', 'Score': '67.8'}}, {'LEADERBOARD': {'Task': 'Template-Based Automatic Search of Compact Semantic Segmentation Architectures', 'Dataset': 'CamVid', 'Metric': 'mean IoU', 'Score': '63.2'}}]\",\n",
       " \"[{'LEADERBOARD': {'Task': 'VTAB (19 tasks)', 'Dataset': '', 'Metric': 'All tasks', 'Score': '79.9900'}}, {'LEADERBOARD': {'Task': 'Oxford Pets', 'Dataset': 'Oxford Pets', 'Metric': '', 'Score': '96.62'}}, {'LEADERBOARD': {'Task': 'Oxford Flowers', 'Dataset': 'Oxford Flowers', 'Metric': '', 'Score': '99.63'}}, {'LEADERBOARD': {'Task': 'ImageNet', 'Dataset': '', 'Metric': 'Acc@1 w/ frozen features', 'Score': '83.6'}}, {'LEADERBOARD': {'Task': 'Stanford Cars', 'Dataset': 'Stanford Cars', 'Metric': '', 'Score': '95.07'}}, {'LEADERBOARD': {'Task': 'VTAB (19 tasks)', 'Dataset': '', 'Metric': 'Natural', 'Score': '83.38'}}, {'LEADERBOARD': {'Task': 'VTAB (19 tasks)', 'Dataset': '', 'Metric': 'Structured', 'Score': '73.25'}}, {'LEADERBOARD': {'Task': 'ImageNet', 'Dataset': '', 'Metric': 'Acc@5', 'Score': '97.6'}}, {'LEADERBOARD': {'Task': 'ImageNet', 'Dataset': '', 'Metric': 'Acc@1', 'Score': '85.4'}}, {'LEADERBOARD': {'Task': 'VTAB (19 tasks)', 'Dataset': '', 'Metric': 'Specialized', 'Score': '87.56'}}, {'LEADERBOARD': {'Task': 'Food101', 'Dataset': 'Food101', 'Metric': '', 'Score': '96.03'}}]\",\n",
       " \"[{'LEADERBOARD': {'Task': 'Diagnostic Analysis', 'Dataset': 'HMDB-51', 'Metric': 'Top 1', 'Score': '39.9'}}, {'LEADERBOARD': {'Task': 'Diagnostic Analysis', 'Dataset': 'HMDB-51', 'Metric': 'Per clip', 'Score': '35.6'}}, {'LEADERBOARD': {'Task': 'Diagnostic Analysis', 'Dataset': 'HMDB-51', 'Metric': 'Top 5', 'Score': '74.4'}}, {'LEADERBOARD': {'Task': 'Diagnostic Analysis', 'Dataset': 'HMDB-51', 'Metric': 'Top 5', 'Score': '70.5'}}, {'LEADERBOARD': {'Task': 'Diagnostic Analysis', 'Dataset': 'HMDB-51', 'Metric': 'Per clip', 'Score': '37.8'}}, {'LEADERBOARD': {'Task': 'Diagnostic Analysis', 'Dataset': 'HMDB-51', 'Metric': 'Top 1', 'Score': '40.3'}}]\",\n",
       " \"[{'LEADERBOARD': {'Task': 'Optimal Learning Rates', 'Dataset': 'various experimental setups', 'Metric': 'learning rate and width multiplier', 'Score': 'qualitatively very similar results'}}, {'LEADERBOARD': {'Task': 'Benchmark Leaderboard Results', 'Dataset': 'ImageNet16x16, ImageNet32x32 and ImageNet64x64', 'Metric': 'Top-1 and Top-5 errors', 'Score': 'similar results'}}, {'LEADERBOARD': {'Task': 'Performance vs. Training Time', 'Dataset': 'different downsampling and network sizes', 'Metric': 'mean Top-5 test error rates', 'Score': 'optimal anytime performance'}}]\",\n",
       " \"[{'LEADERBOARD': {'Task': 'Phantom and brain reconstructions', 'Dataset': 'Real experimental data', 'Metric': 'Image quality', 'Score': 'Improved'}}, {'LEADERBOARD': {'Task': 'Phantom and brain reconstructions', 'Dataset': 'Real experimental data', 'Metric': 'Noise reduction', 'Score': 'Significant'}}]\",\n",
       " 'unanswerable\\n',\n",
       " \"[{'LEADERBOARD': {'Task': 'Hadoop HDFS with Streams & Python', 'Dataset': 'Malstone A', 'Metric': '', 'Score': '87m 29s'}}, {'LEADERBOARD': {'Task': 'Hadoop HDFS with MapReduce', 'Dataset': 'Malstone A', 'Metric': '', 'Score': '454m 13s'}}, {'LEADERBOARD': {'Task': 'Sector with Sphere UDFs', 'Dataset': 'Malstone A', 'Metric': '', 'Score': '33m 40s'}}, {'LEADERBOARD': {'Task': 'Benchmark Leaderboard Results', 'Dataset': '', 'Metric': '', 'Score': ''}}, {'LEADERBOARD': {'Task': 'Sector with Sphere UDFs', 'Dataset': 'Malstone B', 'Metric': '', 'Score': '43m 44s'}}, {'LEADERBOARD': {'Task': 'Hadoop HDFS with Streams & Python', 'Dataset': 'Malstone B', 'Metric': '', 'Score': '142m 32s'}}, {'LEADERBOARD': {'Task': 'Hadoop HDFS with MapReduce', 'Dataset': 'Malstone B', 'Metric': '', 'Score': '840m 50s'}}]\",\n",
       " \"[{'LEADERBOARD': {'Task': 'assignment', 'Dataset': '31+', 'Metric': 'N', 'Score': 13.1}}, {'LEADERBOARD': {'Task': 'convex hull', 'Dataset': '0--1', 'Metric': 'N', 'Score': 687.9}}, {'LEADERBOARD': {'Task': 'assignment', 'Dataset': '0--1', 'Metric': 'N', 'Score': 33.8}}, {'LEADERBOARD': {'Task': 'assignment', 'Dataset': '16--20', 'Metric': 'N', 'Score': 78.3}}, {'LEADERBOARD': {'Task': 'convex hull', 'Dataset': '6--10', 'Metric': 'N', 'Score': 434.1}}, {'LEADERBOARD': {'Task': 'convex hull', 'Dataset': '16--20', 'Metric': 'N', 'Score': 68.8}}, {'LEADERBOARD': {'Task': 'intersection', 'Dataset': '11--15', 'Metric': 'N', 'Score': 27.4}}, {'LEADERBOARD': {'Task': 'intersection', 'Dataset': '0--1', 'Metric': 'N', 'Score': 1389}}, {'LEADERBOARD': {'Task': 'convex hull', 'Dataset': '11--15', 'Metric': 'N', 'Score': 119.5}}, {'LEADERBOARD': {'Task': 'convex hull', 'Dataset': '2--5', 'Metric': 'N', 'Score': 679.7}}, {'LEADERBOARD': {'Task': 'assignment', 'Dataset': '11--15', 'Metric': 'N', 'Score': 20.9}}, {'LEADERBOARD': {'Task': 'convex hull', 'Dataset': '21--25', 'Metric': 'N', 'Score': ''}}, {'LEADERBOARD': {'Task': 'assignment', 'Dataset': '26--30', 'Metric': 'N', 'Score': 59.5}}, {'LEADERBOARD': {'Task': 'convex hull', 'Dataset': '31+', 'Metric': 'N', 'Score': ''}}, {'LEADERBOARD': {'Task': 'intersection', 'Dataset': '2--5', 'Metric': 'N', 'Score': 1752}}, {'LEADERBOARD': {'Task': 'assignment', 'Dataset': '6--10', 'Metric': 'N', 'Score': 385.4}}, {'LEADERBOARD': {'Task': 'convex hull', 'Dataset': '26--30', 'Metric': 'N', 'Score': ''}}, {'LEADERBOARD': {'Task': 'intersection', 'Dataset': '16--20', 'Metric': 'N', 'Score': 1.3}}, {'LEADERBOARD': {'Task': 'intersection', 'Dataset': '6--10', 'Metric': 'N', 'Score': 52.3}}, {'LEADERBOARD': {'Task': 'assignment', 'Dataset': '21--25', 'Metric': 'N', 'Score': 537.4}}, {'LEADERBOARD': {'Task': 'assignment', 'Dataset': '2--5', 'Metric': 'N', 'Score': 601.8}}]\",\n",
       " \"[ {'Task': 'In-Story Sentiment Consistency', 'Dataset': N/A, 'Metric': Standard Deviation', 'Score': N/A}, {'Task': 'Topic-Story Sentiment Consistency', 'Dataset': Various Events, 'Metric': Sentiment Scores', 'Score': Table~ref{tab:sentiment_consistence_with_topic}}, {'Task': N/A, 'Dataset': N/A, 'Metric': N/A, 'Score': Figure~ref{fig:in-story-sentiment}}]\",\n",
       " \"[{'LEADERBOARD': {'Task': 'Proportion of Action', 'Dataset': 'TVSeries', 'Metric': 'mAP', 'Score': '86.1'}}, {'LEADERBOARD': {'Task': 'Proportion of Action', 'Dataset': 'TVSeries', 'Metric': 'mAP', 'Score': '88.9'}}, {'LEADERBOARD': {'Task': 'Proportion of Action', 'Dataset': 'TVSeries', 'Metric': 'mAP', 'Score': '87.2'}}, {'LEADERBOARD': {'Task': 'Proportion of Action', 'Dataset': 'TVSeries', 'Metric': 'mAP', 'Score': '88.3'}}, {'LEADERBOARD': {'Task': 'Proportion of Action', 'Dataset': 'TVSeries', 'Metric': 'mAP', 'Score': '88.4'}}, {'LEADERBOARD': {'Task': 'Proportion of Action', 'Dataset': 'TVSeries', 'Metric': 'mAP', 'Score': '82.1'}}, {'LEADERBOARD': {'Task': 'Proportion of Action', 'Dataset': 'TVSeries', 'Metric': 'mAP', 'Score': '87.7'}}, {'LEADERBOARD': {'Task': 'Proportion of Action', 'Dataset': 'TVSeries', 'Metric': 'mAP', 'Score': '83.5'}}, {'LEADERBOARD': {'Task': 'Proportion of Action', 'Dataset': 'TVSeries', 'Metric': 'mAP', 'Score': '89.0'}}, {'LEADERBOARD': {'Task': 'Proportion of Action', 'Dataset': 'TVSeries', 'Metric': 'mAP', 'Score': '88.7'}}]\",\n",
       " \"[{'LEADERBOARD': {'Task': 'Template-Based Automatic Search of Compact Semantic Segmentation Architectures', 'Dataset': 'CityScapes', 'Metric': 'mean IoU', 'Score': '67.8'}}, {'LEADERBOARD': {'Task': 'Template-Based Automatic Search of Compact Semantic Segmentation Architectures', 'Dataset': 'CamVid', 'Metric': 'mean IoU', 'Score': '63.2'}}]\",\n",
       " \"[{'LEADERBOARD': {'Task': 'DPA-Contest Traces', 'Dataset': '0x10', 'Metric': '+ P[26]+ P[27]+ P[37]+ P[45]+ P[53]+ P[61]+ K[6]+ K[7]+ K[52]+ K[61]', 'Score': '0.0126'}}, {'LEADERBOARD': {'Task': 'DPA-Contest Traces', 'Dataset': '0x10', 'Metric': '+ P[5]+ P[26]+ P[27]+ P[31]+ P[37]+ P[45]+ P[53]+ P[61]+ K[6]+ K[7]+ K[29]+ K[38]+ K[52]+ K[61]', 'Score': '0.0183'}}, {'LEADERBOARD': {'Task': 'DPA-Contest Traces', 'Dataset': '0x20', 'Metric': '+ P[28]+ P[29]+ P[31]+ P[37]+ P[45]+ K[6]+ K[7]+ K[29]+ K[61]', 'Score': '0.0156'}}, {'LEADERBOARD': {'Task': 'DPA-Contest Traces', 'Dataset': '0x10', 'Metric': '+ P[5]+ P[28]+ P[29]+ P[31]+ P[37]+ P[53]+ K[7]+ K[29]+ K[38]+ K[61]', 'Score': '0.0189'}}, {'LEADERBOARD': {'Task': 'DPA-Contest Traces', 'Dataset': '0x20', 'Metric': '+ P[5]+ P[28]+ P[29]+ P[31]+ P[37]+ P[53]+ K[7]+ K[29]+ K[38]+ K[61]', 'Score': '0.0189'}}, {'LEADERBOARD': {'Task': 'DPA-Contest Traces', 'Dataset': '0x10', 'Metric': '+ P[5]+ P[28]+ P[29]+ P[31]+ P[37]+ P[45]+ K[6]+ K[29]+ K[38]+ K[61]', 'Score': '0.0142'}}, {'LEADERBOARD': {'Task': 'DPA-Contest Traces', 'Dataset': '0x20', 'Metric': '+ P[5]+ P[26]+ P[27]+ P[31]+ P[37]+ P[53]+ P[61]+ K[7]+ K[29]+ K[38]+ K[52]+ K[61]', 'Score': '0.0191'}}, {'LEADERBOARD': {'Task': 'DPA-Contest Traces', 'Dataset': '0x20', 'Metric': '+ P[45]+ P[53]+ K[6]+ K[7]+ K[29]+ K[38]+ K[52]', 'Score': '0.0134'}}]\",\n",
       " \"[{'LEADERBOARD': {'Task': 'Template-Based Automatic Search of Compact Semantic Segmentation Architectures', 'Dataset': 'CityScapes', 'Metric': 'mean IoU', 'Score': '67.8'}}, {'LEADERBOARD': {'Task': 'Template-Based Automatic Search of Compact Semantic Segmentation Architectures', 'Dataset': 'CamVid', 'Metric': 'mean IoU', 'Score': '63.2'}}]\",\n",
       " \"[{'LEADERBOARD': {'Task': 'Neural Architecture Search', 'Dataset': '', 'Metric': 'Performance', 'Score': ''}}]\",\n",
       " 'unanswerable\\n',\n",
       " \"[{'LEADERBOARD': {'Task': 'Alignment', 'Dataset': 'OCHuman', 'Metric': 'AP (OCHuman)', 'Score': '0.429'}}, {'LEADERBOARD': {'Task': 'Alignment', 'Dataset': 'OCHuman', 'Metric': 'AP (COCOPerson)', 'Score': '0.489'}}, {'LEADERBOARD': {'Task': 'Alignment', 'Dataset': 'OCHuman', 'Metric': 'AP (COCOPerson)', 'Score': '0.648'}}, {'LEADERBOARD': {'Task': 'Alignment', 'Dataset': 'OCHuman', 'Metric': 'AP (COCOPerson)', 'Score': '0.477'}}, {'LEADERBOARD': {'Task': 'Alignment', 'Dataset': 'OCHuman', 'Metric': 'AP (OCHuman)', 'Score': '0.476'}}, {'LEADERBOARD': {'Task': 'Alignment', 'Dataset': 'OCHuman', 'Metric': 'AP (COCOPerson)', 'Score': '0.497'}}, {'LEADERBOARD': {'Task': 'Alignment', 'Dataset': 'OCHuman', 'Metric': 'AP (COCOPerson)', 'Score': '0.501'}}, {'LEADERBOARD': {'Task': 'Alignment', 'Dataset': 'COCOPerson', 'Metric': 'AP (OCHuman)', 'Score': '0.648'}}, {'LEADERBOARD': {'Task': 'Alignment', 'Dataset': 'OCHuman', 'Metric': 'AP (OCHuman)', 'Score': '0.441'}}, {'LEADERBOARD': {'Task': 'Alignment', 'Dataset': 'OCHuman', 'Metric': 'AP (COCOPerson)', 'Score': '0.431'}}, {'LEADERBOARD': {'Task': 'Alignment', 'Dataset': 'OCHuman', 'Metric': 'AP (OCHuman)', 'Score': '0.436'}}, {'LEADERBOARD': {'Task': 'Alignment', 'Dataset': 'OCHuman', 'Metric': 'AP (OCHuman)', 'Score': '0.403'}}, {'LEADERBOARD': {'Task': 'Alignment', 'Dataset': 'OCHuman', 'Metric': 'AP (OCHuman)', 'Score': '0.437'}}, {'LEADERBOARD': {'Task': 'Alignment', 'Dataset': 'OCHuman', 'Metric': 'AP (OCHuman)', 'Score': '0.411'}}, {'LEADERBOARD': {'Task': 'Alignment', 'Dataset': 'OCHuman', 'Metric': 'AP (COCOPerson)', 'Score': '0.460'}}, {'LEADERBOARD': {'Task': 'Alignment', 'Dataset': 'COCOPerson', 'Metric': 'AP (COCOPerson)', 'Score': '0.431'}}, {'LEADERBOARD': {'Task': 'Alignment', 'Dataset': 'OCHuman', 'Metric': 'AP (OCHuman)', 'Score': '0.393'}}, {'LEADERBOARD': {'Task': 'Alignment', 'Dataset': 'OCHuman', 'Metric': 'AP (OCHuman)', 'Score': '0.420'}}, {'LEADERBOARD': {'Task': 'Alignment', 'Dataset': 'OCHuman', 'Metric': 'AP (COCOPerson)', 'Score': '0.500'}}]\",\n",
       " \"[{'LEADERBOARD': {'Task': 'NAS-101', 'Dataset': 'None', 'Metric': 'Test Accuracy', 'Score': '94.10'}}, {'LEADERBOARD': {'Task': 'NAS-101', 'Dataset': 'None', 'Metric': 'Test Accuracy', 'Score': '93.58'}}, {'LEADERBOARD': {'Task': 'NAS-101', 'Dataset': 'None', 'Metric': 'Test Accuracy', 'Score': '93.72'}}, {'LEADERBOARD': {'Task': 'NAS-101', 'Dataset': 'None', 'Metric': 'Test Accuracy', 'Score': '94.08'}}, {'LEADERBOARD': {'Task': 'NAS-101', 'Dataset': 'None', 'Metric': 'Test Accuracy', 'Score': '93.54'}}, {'LEADERBOARD': {'Task': 'NAS-101', 'Dataset': 'None', 'Metric': 'Test Accuracy', 'Score': '94.05'}}, {'LEADERBOARD': {'Task': 'NAS-101', 'Dataset': 'None', 'Metric': 'Test Accuracy', 'Score': '93.74'}}]\",\n",
       " \"[{'LEADERBOARD': {'Task': 'CB- MANETs with sufficient caches of a file', 'Dataset': '', 'Metric': 'robustness', 'Score': 'performance equals that of unrestricted coding'}}, {'LEADERBOARD': {'Task': 'Unrestricted coding vs. Full cache coding vs. Source only coding vs. No coding', 'Dataset': '', 'Metric': 'robustness', 'Score': 'full protection against pollution attacks'}}]\"]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df[\"annotation\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
